#!/bin/bash
# ==================================================================================================
# ðŸŒ€ Apache Airflow â€” Docker Management & Best Practices Guide
# --------------------------------------------------------------------------------------------------
# This guide explains how to manage Apache Airflow using Docker, covering both Development and
# Production setups:
#
# - Airflow-Docker-Dev  â†’ Local testing and debugging
# - Airflow-Docker-Prod â†’ Stable, continuous operation
#
# Each command below includes:
#   âœ… What it does
#   ðŸ“… When to use it
#   âš ï¸  When *not* to use it
#
# Author: Prasanna
# Environments: Airflow-Docker-Dev / Airflow-Docker-Prod
# ==================================================================================================

# ==================================================================================================
# ðŸ§­ Step 1 â€” Navigate to Your Airflow Folder
# --------------------------------------------------------------------------------------------------
# âœ… What It Does:
#    Moves you into your Airflow Docker project directory.
# ðŸ“… When to Use:
#    Always before running any docker-compose commands.
# âš ï¸ When NOT to Use:
#    If youâ€™re already in the correct directory.
# ==================================================================================================
cd "C:/Users/prasa/Root/Airflow-Docker-Prod"

# ==================================================================================================
# ðŸ§© Step 2 â€” Initialize the Airflow Metadata Database
# --------------------------------------------------------------------------------------------------
# âœ… When to Use:
#   - First-time setup (new environment)
#   - After deleting volumes (`docker compose down -v`)
#   - After changing DB location or engine (SQLite â†’ MySQL/Postgres)
#
# ðŸ§  What It Does:
#   - Creates Airflowâ€™s internal metadata tables (DAGs, users, jobs, etc.)
#   - `--rm` cleans up the temporary container after completion
#
# âš ï¸ When NOT to Use:
#   - After Airflow is configured and running (resets metadata)
# ==================================================================================================
docker compose run --rm airflow-init

# ==================================================================================================
# ðŸŸ¢ Step 3 â€” Start Airflow Containers
# --------------------------------------------------------------------------------------------------
# Option A â€” Background Mode (Recommended)
# âœ… When to Use:
#   - Day-to-day operation (especially in production)
#   - You want Airflow to run continuously in the background
#
# ðŸ§  What It Does:
#   - Starts all containers (webserver, scheduler, etc.) in detached mode
#   - Frees up your terminal
#
# âš ï¸ When NOT to Use:
#   - When debugging DAG load or environment issues
# ==================================================================================================
docker compose up -d

# --------------------------------------------------------------------------------------------------
# Option B â€” Foreground Mode (Debugging)
# âœ… When to Use:
#   - During troubleshooting or first-time setup
#   - When you need logs in real time
#
# âš ï¸ When NOT to Use:
#   - In production or long-running sessions (stops when terminal closes)
# --------------------------------------------------------------------------------------------------
# docker compose up

# ==================================================================================================
# ðŸ›‘ Step 4 â€” Stop Airflow Containers
# --------------------------------------------------------------------------------------------------
# âœ… When to Use:
#   - To stop Airflow cleanly and preserve all data/logs
# ðŸ§  What It Does:
#   - Stops and removes containers but keeps metadata DB, logs, DAGs
# âš ï¸ When NOT to Use:
#   - When you expect a full reset (use `down -v` instead)
# ==================================================================================================
docker compose down

# ==================================================================================================
# ðŸ’£ Step 5 â€” Full Environment Reset (Deletes Database)
# --------------------------------------------------------------------------------------------------
# âœ… When to Use:
#   - To completely wipe and reinitialize Airflow (clean start)
# âš ï¸ When NOT to Use:
#   - If you want to preserve metadata, DAG runs, or user accounts
# ==================================================================================================
# docker compose down -v

# ==================================================================================================
# ðŸ” Step 6 â€” Restart or Rebuild Airflow
# --------------------------------------------------------------------------------------------------
# Restart Cleanly
# âœ… Use when restarting after small edits to environment variables or compose file.
# ==================================================================================================
# docker compose down
# docker compose up -d

# Rebuild Images (after Dockerfile or dependency changes)
# âœ… Use when adding new Python dependencies or modifying Dockerfile.
# ==================================================================================================
# docker compose build --no-cache
# docker compose up -d

# ==================================================================================================
# ðŸ‘¤ Step 7 â€” Create an Admin User
# --------------------------------------------------------------------------------------------------
# âœ… When to Use:
#   - After DB initialization (first-time setup or reset)
#   - When adding new admin users
#
# ðŸ§  What It Does:
#   - Creates user directly inside the running Airflow webserver container
#
# âš ï¸ When NOT to Use:
#   - Before DB initialization (fails)
#   - When overwriting existing usernames
# ==================================================================================================
docker exec -it airflow-webserver-prod airflow users create \
  --username xxx \
  --firstname xxxx \
  --lastname xxx \
  --role Admin \
  --email prasanna@xxx.com \
  --password "your_secure_password"

# ==================================================================================================
# ðŸŒ Step 8 â€” Access the Airflow Web UI
# --------------------------------------------------------------------------------------------------
# Dev UI:  http://localhost:8080
# Prod UI: http://localhost:8081
# Login with the credentials created above.
# ==================================================================================================

# ==================================================================================================
# ðŸ§¹ Step 9 â€” Maintenance & Inspection
# --------------------------------------------------------------------------------------------------
# Task                     | Command                                              | Description
# --------------------------|------------------------------------------------------|-----------------------------
# ðŸ§© List containers        | docker ps                                            | Shows running containers
# ðŸ” View logs              | docker logs -f airflow-webserver-prod               | Follow logs in real time
# ðŸš Open shell             | docker exec -it airflow-webserver-prod bash         | Access container terminal
# ðŸ’¾ Backup DB              | copy .\db\airflow_prod.db .\db\airflow_prod_backup_2025_11_05.db | Save metadata DB
# ðŸ”„ Restore DB             | copy .\db\airflow_prod_backup_2025_11_05.db .\db\airflow_prod.db | Replace DB from backup
# ==================================================================================================

# ==================================================================================================
# ðŸ§© Step 10 â€” Environment Configuration (Dev vs Prod)
# --------------------------------------------------------------------------------------------------
# Setting         | Dev                             | Prod                              | Notes
# ----------------|----------------------------------|-----------------------------------|----------------------------------------
# Executor        | SequentialExecutor               | LocalExecutor / CeleryExecutor    | Sequential = Simple; Local = Parallel
# Database        | /db/airflow_dev.db               | /db/airflow_prod.db               | Separate DB files
# Web UI Port     | 8080                             | 8081                              | Avoid conflicts
# Purpose         | Testing & iteration               | Stable scheduled runs             | Keep isolated
# ==================================================================================================

# ==================================================================================================
# ðŸ§  Step 11 â€” Common Issues & Fixes
# --------------------------------------------------------------------------------------------------
# Error                                 | Cause                        | Solution
# --------------------------------------|-------------------------------|-----------------------------------------
# Invalid username/password             | DB reinitialized              | Recreate user
# DAG not found                         | Wrong repo mount              | Verify volume mapping & sys.path
# Cannot use SQLite with LocalExecutor   | Wrong executor type           | Switch to MySQL/Postgres
# FileNotFoundError: google-ads.yaml     | Secret not mounted correctly  | Confirm /opt/airflow/secrets volume
# UI not loading                         | Port conflict                 | Change port 8080/8081
# ==================================================================================================

# ==================================================================================================
# ðŸ§© Step 12 â€” Typical Full Workflow
# --------------------------------------------------------------------------------------------------
# 1ï¸âƒ£ Move to Airflow folder
cd "C:/Users/prasa/Root/Airflow-Docker-Prod"

# 2ï¸âƒ£ Initialize Airflow DB (only once)
docker compose run --rm airflow-init

# 3ï¸âƒ£ Start Airflow in background
docker compose up -d

# 4ï¸âƒ£ Create admin user
docker exec -it airflow-webserver-prod airflow users create \
  --username xxx \
  --firstname xxx \
  --lastname xxx \
  --role Admin \
  --email prasanna@xxx.com \
  --password "your_secure_password"

# 5ï¸âƒ£ Access web UI: http://localhost:8081
# 6ï¸âƒ£ Stop containers when needed
docker compose down
# ==================================================================================================

# ==================================================================================================
# ðŸ§© Step 13 â€” Quick Reference Cheat Sheet
# --------------------------------------------------------------------------------------------------
# Purpose               | Command                                                  | Detached? | Notes
# ----------------------|----------------------------------------------------------|-----------|----------------------------
# Initialize DB         | docker compose run --rm airflow-init                     | âŒ        | One-time setup/reset
# Start Airflow         | docker compose up -d                                     | âœ…        | Background (Prod)
# Start Airflow (debug) | docker compose up                                        | âŒ        | Foreground logs
# Stop Airflow          | docker compose down                                      | âŒ        | Graceful stop
# Full Reset            | docker compose down -v                                   | âŒ        | Destroys DB
# Restart Airflow       | docker compose down && docker compose up -d              | âœ…        | Refresh containers
# Rebuild Image         | docker compose build --no-cache && docker compose up -d  | âœ…        | After Dockerfile change
# Create Admin User     | docker exec -it airflow-webserver-prod airflow users create ... | âŒ | For UI login
# List Containers       | docker ps                                                | âŒ        | See running services
# Follow Logs           | docker logs -f airflow-webserver-prod                    | âŒ        | Debug issues
# ==================================================================================================

# ==================================================================================================
# ðŸ§  Best Practices
# --------------------------------------------------------------------------------------------------
# âœ… Always backup your airflow_*.db before rebuilds or resets.
# âœ… Use `-d` for stability, `up` for troubleshooting.
# âœ… Keep Dev and Prod isolated (DBs, secrets, ports).
# âœ… Add to .gitignore:
#     *.env
#     *.json
#     *.yaml
#     db/
#     logs/
#     secrets/
# âš ï¸ Avoid `docker compose down -v` unless you truly want a blank Airflow instance.
# ==================================================================================================

# ==================================================================================================
# FERNET KEY Related
# --------------------------------------------------------------------------------------------------

# To Generate AIRFLOW_FERNET_KEY follow the below steps:

# The below will install python if python was not found as Docker image

docker run --rm python:3.10 python -c "from cryptography.fernet import Fernet; print(Fernet.generate_key().decode())"

# The above will install cyrtopgraphy if not installed previously and generates AIRFLOW_FERNET_KEY

docker run --rm python:3.10 sh -c "pip install cryptography >/dev/null 2>&1 && python -c 'from cryptography.fernet import Fernet; print(Fernet.generate_key().decode())'"

# Note: If your loval venv uses 3.9 but you have installed python 3.10 image in docker - I would suggest to keep both local and docker image using the same version
# Follow the below steps to remove the previously installed version 3.10 and install 3.9.

docker rmi python:3.10

# After removing 3.10 you can verify with:

docker images

# Now you will need to install Python 3.9 image - the below code will install python 3.9 if not found and it will generate AIRFLOW_FERNET_KEY

docker run --rm python:3.9 sh -c "pip install cryptography >/dev/null 2>&1 && python - << 'EOF'
from cryptography.fernet import Fernet
print(Fernet.generate_key().decode())
EOF"

# If you are confident that python and cyrptography has already been installed then use the below code
# The below can also be used to re-generate AIRFLOW_FERNET_KEY

py -c "from cryptography.fernet import Fernet; print(Fernet.generate_key().decode())"

# ==================================================================================================


# ==================================================================================================
# Stop and Destroy Volumes:
# --------------------------------------------------------------------------------------------------

docker compose down --volumes --remove-orphans

# Start Fresh:

docker compose up -d --build

# ==================================================================================================